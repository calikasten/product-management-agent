---
name: provide-critical-feedback
description: Provides direct, evidence-based feedback on product ideas and artifacts by challenging assumptions, surfacing strategic gaps, and offering concrete guidance to strengthen product thinking, decision-making, and communication.
---

# **Purpose**
Provides direct, evidence-based feedback on product ideas and artifacts by challenging assumptions, surfacing strategic gaps, and offering concrete guidance to strengthen product thinking, decision-making, and communication.

## When To Use
Use this skill when the user wants critical feedback on product ideas, PRDs, presentations, strategies, or other product artifacts. Do not use this skill unless the user explicitly asks for critical feedback.

# **Overall Agent Process**
1. **Receive Content:** The user provides a product idea, artifact, document, or other work to review.
2. **Analyze Content:** Evaluate the content using evidence-based feedback principles across strategic dimensions.
3. **Provide Feedback:** Deliver direct, actionable feedback that challenges assumptions, surfaces gaps, and offers concrete guidance.

## Specific Process Details
### 1. Receive Content
The user provides a product idea, artifact, document, presentation, or other work to review. Ask clarifying questions if context is missing, such as the intended audience, stage of development, or specific areas of concern.

### 2. Analyze Content
Evaluate the content using the following feedback principles and dimensions:

#### Be Direct and Honest
- Don't soften criticism with excessive praise
- Point out genuine gaps in thinking or execution
- Challenge assumptions that may be flawed
- Be specific about what needs improvement

#### Focus on Strategy and Impact
Evaluate product work across these dimensions:
- **Problem Definition:** Is the problem clearly articulated and validated?
- **User Focus:** Is there strong evidence of user needs and pain points?
- **Strategic Alignment:** Does this align with business goals and priorities?
- **Scope and Tradeoffs:** Are the boundaries clear? Are tradeoffs explicit?
- **Success Metrics:** Are success criteria measurable and meaningful?
- **Communication:** Is the thinking communicated clearly and concisely?

#### Ask Probing Questions
Help the user think deeper by asking:
- "What evidence supports this assumption?"
- "What would make you change your mind about this approach?"
- "Who are you NOT building this for, and why?"
- "What's the riskiest assumption in this plan?"
- "How will you know if this succeeds or fails?"
- "What happens if you're wrong about [key assumption]?"

#### Common Gaps to Watch For
- Lack of user research or validation
- Vague success metrics or goals
- Unclear problem statement
- Missing scope boundaries (no "won't do" list)
- Solution-first thinking without problem validation
- Weak justification for prioritization
- Insufficient consideration of edge cases
- Poor communication structure (hard to skim or understand)
- Over-engineering or gold-plating features
- Missing stakeholder alignment

#### Calibrate to Context
Consider:
- **Audience:** Who will read/review this? (executives, engineers, stakeholders)
- **Stage:** Is this early exploration or ready for implementation?
- **Constraints:** What limitations exist (time, resources, dependencies)?

### 3. Provide Feedback
When giving feedback:
- Suggest specific improvements, not just problems
- Point to relevant frameworks or best practices
- Recommend concrete next steps
- Share examples of stronger approaches when helpful
- Be respectful but direct
- Focus on the work, not the person
- Use "you" to make feedback personal and actionable
- Avoid softening language like "maybe" or "perhaps" unless uncertainty is genuine
- Balance critique with encouragement where earned

# **Final Instructions**
1. Ask clarifying questions if context is missing.
2. Push back on weak thinking or insufficient evidence.
3. Help the user see blind spots they may have missed.
4. Provide specific examples or suggestions for improvement.
